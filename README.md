# ğŸ¬ VidRAG â€” Chat with YouTube Videos using RAG + LangChain LCEL + FastAPI

## ğŸ“– Overview
**VidRAG** (Video Retrieval-Augmented Generation) is an AI system that allows you to **ask questions about YouTube videos** and receive **accurate, context-grounded answers** â€” all powered by **LangChain**, **OpenAI**, **Pinecone**, and **FastAPI**.

Instead of watching an entire video, you can now simply ask:
> â€œWhat are the key points discussed?â€  
> â€œWhen does the speaker explain transformers?â€  
> â€œSummarize the conclusion section.â€

VidRAG intelligently retrieves transcript segments, finds semantically relevant chunks, and uses **RAG (Retrieval-Augmented Generation)** to generate timestamped, factual responses.

---

## ğŸš€ Features

âœ… **Real-time Q&A** over YouTube videos  
âœ… **Token-based text splitting** for better chunking  
âœ… **Pinecone** vector database for semantic search  
âœ… **LangChain LCEL (Runnable pipeline)** for clean orchestration  
âœ… **FastAPI** backend with Swagger UI  
âœ… **Timestamped and context-backed responses**  
âœ… **Modular architecture** â€” easy to extend or replace components  

---

## ğŸ§  Architecture

ğŸ“ VidRAG/
â”‚
â”œâ”€â”€ modules/
â”‚ â”œâ”€â”€ loader.py # Loads YouTube transcripts
â”‚ â”œâ”€â”€ splitter.py # Splits text into token-aware chunks
â”‚ â”œâ”€â”€ embeddings.py # Generates embeddings using OpenAI
â”‚ â”œâ”€â”€ vector_store.py # Stores embeddings in Pinecone
â”‚ â”œâ”€â”€ retriever.py # Retrieves top-k similar chunks
â”‚ â””â”€â”€ rag_chain.py # Constructs and runs the RAG pipeline
â”‚
â”œâ”€â”€ app.py # FastAPI app for serving VidRAG
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md # Project documentation



---

## âš™ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Language** | Python 3.10+ |
| **Framework** | FastAPI |
| **LLM Orchestration** | LangChain (LCEL, Runnables) |
| **Embeddings** | OpenAI (text-embedding-3-small) |
| **Vector Database** | Pinecone |
| **Transcript Fetching** | YouTube API |
| **Frontend Docs** | Swagger UI (auto-generated by FastAPI) |

---

## ğŸ§© How It Works

1. **Load Transcript:**  
   Extracts the transcript from a YouTube video using its URL.  

2. **Chunk Text:**  
   Splits the transcript into semantically meaningful, token-based chunks.  

3. **Embed Chunks:**  
   Generates embeddings using `text-embedding-3-small`.  

4. **Store in Vector DB:**  
   Saves embeddings in Pinecone for efficient semantic search.  

5. **Retrieve Similar Chunks:**  
   Uses a similarity-based retriever (`k=2` or configurable).  

6. **Generate Answer:**  
   Uses GPT-4o-mini via LangChain LCEL to compose answers grounded in retrieved context.  

7. **Serve via FastAPI:**  
   Exposes endpoints like `/ask` for user queries with responses.

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/BilalAhmed7072/VidRAG.git
cd VidRAG

2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set up environment variables
Create a .env file in the project root with the following keys:

OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
YOUTUBE_API_KEY=your_youtube_api_key
PINECONE_INDEX_NAME=vidrag-index

5ï¸âƒ£ Run the FastAPI server
uvicorn app:app --reload
